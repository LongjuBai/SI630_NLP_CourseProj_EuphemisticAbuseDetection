{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "from huggingface_hub import interpreter_login\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/longju/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token = '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')\n",
    "\n",
    "# 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\n",
    "# interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59963db886024304883665ba817fb1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm AI assistant designed for in-context learning and chain of thoughts. I can learn from the given examples and work on questions step by step. I'm here to help you with your queries, provide explanations, and assist you in building a chain of thoughts. I can also learn from the examples and context provided, and use that knowledge to answer follow-up questions.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are AI assistant designed for in-context learning and chain of thoughs, you can learn from the given exammples and work on questions step by step\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thanks for asking! I'm a large language model, so I don't have feelings like humans do, but I'm always happy to chat and help with any questions or tasks you have. How about you? How's your day going so far?\n"
     ]
    }
   ],
   "source": [
    "def get_completion(user_prompt):\n",
    "    \n",
    "    input_message = user_prompt\n",
    "\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are AI assistant designed for in-context learning, you can learn from the few shot examples to generated similar contents\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{input_message}\"},\n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Hey how are you doing today?\"\n",
    "responses = get_completion(prompt)\n",
    "print(responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_examples(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        examples = file.read().strip()\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dataset_csv, examples_file, output_csv):\n",
    "    # Read the dataset CSV\n",
    "    df = pd.read_csv(dataset_csv)\n",
    "    # df = df.head(5)\n",
    "\n",
    "    examples = load_examples(examples_file)\n",
    "    # Initialize lists to store explanations and predictions\n",
    "    \n",
    "    \n",
    "    explanations = []\n",
    "    predictions = []\n",
    "    \n",
    "    # Iterate over each row in the dataset\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating predictions\"):\n",
    "        # Extract the text from the row\n",
    "        text = row['text']\n",
    "        \n",
    "        # Generate the completion using the provided prompt and get_completion function\n",
    "        prompt = f\"{examples}\\n\\n\" \\\n",
    "                 f\"Please follow the INSTRUCTION and think step by step: given a SENTENCE, first output an explanation about whether you think the given SENTENCE is labeled as abuse, then output the label PREDICTION\\n\\nINSTRUCTION: Think step by step: given the following SENTENCE, first output an explanation about whether you think the given SENTENCE is labeled as abuse, then output the label PREDICTION\\nSENTENCE: {text}\\nEXPLANATION: \\nPREDICTION: \"\n",
    "        completion = get_completion(prompt)\n",
    "        \n",
    "        # Extract the explanation and prediction from the completion\n",
    "        explanation = completion.split(\"EXPLANATION: \")[-1].split(\"PREDICTION:\")[0].strip()\n",
    "        prediction = completion.split(\"PREDICTION:\")[-1].strip()\n",
    "\n",
    "        if prediction == \"NONE\":\n",
    "            prediction = \"NONE ABUSE\"\n",
    "        \n",
    "        # Append the explanation and prediction to their respective lists\n",
    "        explanations.append(explanation)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    # Add explanations and predictions as columns to the DataFrame\n",
    "    df['explanations'] = explanations\n",
    "    df['predictions'] = predictions\n",
    "    display(df)\n",
    "    # Save the DataFrame with explanations and predictions\n",
    "    df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_csv = '../../dataset/train_dev/test_set.csv'\n",
    "output_csv = 'llama_cot_prediction_test.csv'\n",
    "# output_csv = 'llama_cot_prediction.csv'\n",
    "examples_file = 'cot_FewShot_prompt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions:   0%|          | 0/360 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   0%|          | 1/360 [00:02<13:04,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   1%|          | 2/360 [00:04<15:00,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   1%|          | 3/360 [00:07<14:38,  2.46s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   1%|          | 4/360 [00:10<15:06,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   1%|▏         | 5/360 [00:12<14:39,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   2%|▏         | 6/360 [00:14<14:15,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   2%|▏         | 7/360 [00:17<15:37,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   2%|▏         | 8/360 [00:20<15:49,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   2%|▎         | 9/360 [00:23<15:47,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   3%|▎         | 10/360 [00:27<18:13,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   3%|▎         | 11/360 [00:30<17:31,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   3%|▎         | 12/360 [00:32<17:00,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   4%|▎         | 13/360 [00:35<17:12,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   4%|▍         | 14/360 [00:38<16:09,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   4%|▍         | 15/360 [00:41<16:47,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   4%|▍         | 16/360 [00:44<16:41,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   5%|▍         | 17/360 [00:47<17:04,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   5%|▌         | 18/360 [00:50<17:17,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   5%|▌         | 19/360 [00:53<16:44,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   6%|▌         | 20/360 [00:55<15:42,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   6%|▌         | 21/360 [00:59<17:08,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   6%|▌         | 22/360 [01:01<16:08,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   6%|▋         | 23/360 [01:04<15:49,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   7%|▋         | 24/360 [01:06<14:41,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   7%|▋         | 25/360 [01:08<13:38,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   7%|▋         | 26/360 [01:11<14:11,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   8%|▊         | 27/360 [01:14<13:50,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   8%|▊         | 28/360 [01:16<14:14,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   8%|▊         | 29/360 [01:18<13:28,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   8%|▊         | 30/360 [01:21<13:46,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   9%|▊         | 31/360 [01:24<13:41,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   9%|▉         | 32/360 [01:26<13:28,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   9%|▉         | 33/360 [01:28<13:15,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:   9%|▉         | 34/360 [01:31<13:30,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  10%|▉         | 35/360 [01:34<13:59,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  10%|█         | 36/360 [01:36<13:39,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  10%|█         | 37/360 [01:38<13:12,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  11%|█         | 38/360 [01:41<13:33,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  11%|█         | 39/360 [01:44<13:42,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  11%|█         | 40/360 [01:47<14:36,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  11%|█▏        | 41/360 [01:49<14:15,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  12%|█▏        | 42/360 [01:52<14:16,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  12%|█▏        | 43/360 [01:55<14:00,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  12%|█▏        | 44/360 [01:59<16:09,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  12%|█▎        | 45/360 [02:01<15:09,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  13%|█▎        | 46/360 [02:04<14:56,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  13%|█▎        | 47/360 [02:07<14:23,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  13%|█▎        | 48/360 [02:09<14:38,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  14%|█▎        | 49/360 [02:12<14:53,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  14%|█▍        | 50/360 [02:15<14:34,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  14%|█▍        | 51/360 [02:18<14:37,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  14%|█▍        | 52/360 [02:21<14:28,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  15%|█▍        | 53/360 [02:24<15:30,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  15%|█▌        | 54/360 [02:27<14:23,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  15%|█▌        | 55/360 [02:29<13:48,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  16%|█▌        | 56/360 [02:32<14:03,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  16%|█▌        | 57/360 [02:35<14:18,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  16%|█▌        | 58/360 [02:38<14:17,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  16%|█▋        | 59/360 [02:41<13:53,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  17%|█▋        | 60/360 [02:44<14:12,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  17%|█▋        | 61/360 [02:46<13:56,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  17%|█▋        | 62/360 [02:49<14:27,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  18%|█▊        | 63/360 [02:52<14:09,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  18%|█▊        | 64/360 [02:55<14:05,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  18%|█▊        | 65/360 [02:57<13:24,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  18%|█▊        | 66/360 [03:01<13:56,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  19%|█▊        | 67/360 [03:03<12:58,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  19%|█▉        | 68/360 [03:05<12:36,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  19%|█▉        | 69/360 [03:07<11:58,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  19%|█▉        | 70/360 [03:10<12:20,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  20%|█▉        | 71/360 [03:13<12:25,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  20%|██        | 72/360 [03:15<12:34,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  20%|██        | 73/360 [03:19<13:10,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  21%|██        | 74/360 [03:22<13:51,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  21%|██        | 75/360 [03:24<12:53,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  21%|██        | 76/360 [03:27<13:34,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  21%|██▏       | 77/360 [03:30<12:43,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  22%|██▏       | 78/360 [03:32<12:04,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  22%|██▏       | 79/360 [03:35<12:19,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  22%|██▏       | 80/360 [03:38<12:56,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  22%|██▎       | 81/360 [03:40<12:43,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  23%|██▎       | 82/360 [03:43<12:59,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  23%|██▎       | 83/360 [03:46<12:13,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  23%|██▎       | 84/360 [03:48<11:51,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  24%|██▎       | 85/360 [03:50<11:36,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  24%|██▍       | 86/360 [03:53<11:18,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  24%|██▍       | 87/360 [03:56<11:34,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  24%|██▍       | 88/360 [03:59<12:28,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  25%|██▍       | 89/360 [04:01<12:00,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  25%|██▌       | 90/360 [04:04<12:18,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  25%|██▌       | 91/360 [04:07<12:22,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  26%|██▌       | 92/360 [04:10<13:06,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  26%|██▌       | 93/360 [04:13<12:23,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  26%|██▌       | 94/360 [04:16<12:21,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  26%|██▋       | 95/360 [04:18<11:47,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  27%|██▋       | 96/360 [04:20<11:26,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  27%|██▋       | 97/360 [04:23<11:22,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  27%|██▋       | 98/360 [04:26<12:31,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  28%|██▊       | 99/360 [04:29<12:08,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  28%|██▊       | 100/360 [04:31<11:18,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  28%|██▊       | 101/360 [04:34<11:54,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  28%|██▊       | 102/360 [04:37<12:00,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  29%|██▊       | 103/360 [04:40<11:37,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  29%|██▉       | 104/360 [04:43<12:33,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  29%|██▉       | 105/360 [04:46<12:28,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  29%|██▉       | 106/360 [04:50<12:58,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  30%|██▉       | 107/360 [04:52<12:14,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  30%|███       | 108/360 [04:54<11:33,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  30%|███       | 109/360 [04:57<11:31,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  31%|███       | 110/360 [05:00<11:02,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  31%|███       | 111/360 [05:02<10:57,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  31%|███       | 112/360 [05:05<11:21,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  31%|███▏      | 113/360 [05:08<11:12,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  32%|███▏      | 114/360 [05:11<11:21,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  32%|███▏      | 115/360 [05:14<11:19,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  32%|███▏      | 116/360 [05:16<10:33,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  32%|███▎      | 117/360 [05:18<10:08,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  33%|███▎      | 118/360 [05:20<09:48,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  33%|███▎      | 119/360 [05:23<09:37,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  33%|███▎      | 120/360 [05:25<10:01,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  34%|███▎      | 121/360 [05:28<10:07,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  34%|███▍      | 122/360 [05:30<09:56,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  34%|███▍      | 123/360 [05:33<09:35,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  34%|███▍      | 124/360 [05:35<09:32,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  35%|███▍      | 125/360 [05:38<09:30,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  35%|███▌      | 126/360 [05:40<09:07,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  35%|███▌      | 127/360 [05:43<09:48,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  36%|███▌      | 128/360 [05:45<09:41,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  36%|███▌      | 129/360 [05:48<09:47,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  36%|███▌      | 130/360 [05:51<10:09,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  36%|███▋      | 131/360 [05:54<10:31,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  37%|███▋      | 132/360 [05:56<10:25,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  37%|███▋      | 133/360 [05:59<10:06,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  37%|███▋      | 134/360 [06:02<10:21,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  38%|███▊      | 135/360 [06:04<10:07,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  38%|███▊      | 136/360 [06:07<10:12,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  38%|███▊      | 137/360 [06:10<10:17,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  38%|███▊      | 138/360 [06:12<09:52,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  39%|███▊      | 139/360 [06:15<09:41,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  39%|███▉      | 140/360 [06:17<08:56,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  39%|███▉      | 141/360 [06:19<08:35,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  39%|███▉      | 142/360 [06:22<09:33,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  40%|███▉      | 143/360 [06:25<09:48,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  40%|████      | 144/360 [06:27<09:06,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  40%|████      | 145/360 [06:31<09:48,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  41%|████      | 146/360 [06:34<10:00,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  41%|████      | 147/360 [06:37<10:08,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  41%|████      | 148/360 [06:39<09:50,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  41%|████▏     | 149/360 [06:42<09:33,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  42%|████▏     | 150/360 [06:44<09:18,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  42%|████▏     | 151/360 [06:47<09:39,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  42%|████▏     | 152/360 [06:50<09:22,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  42%|████▎     | 153/360 [06:53<09:29,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  43%|████▎     | 154/360 [06:55<09:20,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  43%|████▎     | 155/360 [06:58<08:42,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  43%|████▎     | 156/360 [07:01<09:27,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  44%|████▎     | 157/360 [07:03<09:00,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  44%|████▍     | 158/360 [07:06<09:14,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  44%|████▍     | 159/360 [07:09<09:00,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  44%|████▍     | 160/360 [07:11<08:24,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  45%|████▍     | 161/360 [07:14<09:09,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  45%|████▌     | 162/360 [07:17<09:09,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  45%|████▌     | 163/360 [07:19<08:38,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  46%|████▌     | 164/360 [07:22<08:28,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  46%|████▌     | 165/360 [07:25<08:46,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  46%|████▌     | 166/360 [07:27<08:08,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  46%|████▋     | 167/360 [07:29<08:05,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  47%|████▋     | 168/360 [07:32<07:44,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  47%|████▋     | 169/360 [07:34<07:56,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  47%|████▋     | 170/360 [07:37<08:38,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  48%|████▊     | 171/360 [07:40<08:09,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  48%|████▊     | 172/360 [07:42<08:04,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  48%|████▊     | 173/360 [07:45<08:32,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  48%|████▊     | 174/360 [07:48<08:27,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  49%|████▊     | 175/360 [07:51<08:35,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  49%|████▉     | 176/360 [07:53<07:53,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  49%|████▉     | 177/360 [07:56<07:41,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  49%|████▉     | 178/360 [07:59<08:26,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  50%|████▉     | 179/360 [08:01<08:01,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  50%|█████     | 180/360 [08:04<08:02,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  50%|█████     | 181/360 [08:07<07:52,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  51%|█████     | 182/360 [08:09<07:45,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  51%|█████     | 183/360 [08:12<07:32,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  51%|█████     | 184/360 [08:14<07:19,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  51%|█████▏    | 185/360 [08:16<07:22,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  52%|█████▏    | 186/360 [08:19<07:16,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  52%|█████▏    | 187/360 [08:22<07:20,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  52%|█████▏    | 188/360 [08:24<07:22,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  52%|█████▎    | 189/360 [08:27<07:12,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  53%|█████▎    | 190/360 [08:30<07:28,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  53%|█████▎    | 191/360 [08:32<07:11,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  53%|█████▎    | 192/360 [08:35<07:26,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  54%|█████▎    | 193/360 [08:37<07:16,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  54%|█████▍    | 194/360 [08:40<07:09,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  54%|█████▍    | 195/360 [08:43<07:14,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  54%|█████▍    | 196/360 [08:45<07:11,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  55%|█████▍    | 197/360 [08:48<07:10,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  55%|█████▌    | 198/360 [08:50<06:41,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  55%|█████▌    | 199/360 [08:52<06:26,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  56%|█████▌    | 200/360 [08:56<07:22,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  56%|█████▌    | 201/360 [08:58<06:58,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  56%|█████▌    | 202/360 [09:01<07:01,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  56%|█████▋    | 203/360 [09:03<06:53,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  57%|█████▋    | 204/360 [09:06<06:50,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  57%|█████▋    | 205/360 [09:08<06:38,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  57%|█████▋    | 206/360 [09:11<06:36,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  57%|█████▊    | 207/360 [09:14<06:30,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  58%|█████▊    | 208/360 [09:16<06:20,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  58%|█████▊    | 209/360 [09:19<06:20,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  58%|█████▊    | 210/360 [09:22<06:43,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  59%|█████▊    | 211/360 [09:25<06:52,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  59%|█████▉    | 212/360 [09:28<07:22,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  59%|█████▉    | 213/360 [09:31<07:06,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  59%|█████▉    | 214/360 [09:33<06:56,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  60%|█████▉    | 215/360 [09:36<06:46,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  60%|██████    | 216/360 [09:39<06:41,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  60%|██████    | 217/360 [09:41<06:25,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  61%|██████    | 218/360 [09:44<06:12,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  61%|██████    | 219/360 [09:47<06:39,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  61%|██████    | 220/360 [09:50<06:24,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  61%|██████▏   | 221/360 [09:52<06:18,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  62%|██████▏   | 222/360 [09:55<06:19,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  62%|██████▏   | 223/360 [09:58<06:32,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  62%|██████▏   | 224/360 [10:01<06:17,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  62%|██████▎   | 225/360 [10:04<06:11,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  63%|██████▎   | 226/360 [10:07<06:33,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  63%|██████▎   | 227/360 [10:10<06:47,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  63%|██████▎   | 228/360 [10:13<06:23,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  64%|██████▎   | 229/360 [10:15<05:53,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  64%|██████▍   | 230/360 [10:17<05:36,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  64%|██████▍   | 231/360 [10:20<05:40,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  64%|██████▍   | 232/360 [10:24<06:18,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  65%|██████▍   | 233/360 [10:27<06:04,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  65%|██████▌   | 234/360 [10:29<05:54,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  65%|██████▌   | 235/360 [10:32<05:33,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  66%|██████▌   | 236/360 [10:34<05:23,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  66%|██████▌   | 237/360 [10:37<05:27,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  66%|██████▌   | 238/360 [10:40<05:26,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  66%|██████▋   | 239/360 [10:42<05:23,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  67%|██████▋   | 240/360 [10:46<05:51,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  67%|██████▋   | 241/360 [10:48<05:41,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  67%|██████▋   | 242/360 [10:51<05:22,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  68%|██████▊   | 243/360 [10:54<05:18,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  68%|██████▊   | 244/360 [10:56<05:14,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  68%|██████▊   | 245/360 [10:58<04:53,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  68%|██████▊   | 246/360 [11:01<04:43,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  69%|██████▊   | 247/360 [11:03<04:42,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  69%|██████▉   | 248/360 [11:06<04:38,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  69%|██████▉   | 249/360 [11:09<04:59,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  69%|██████▉   | 250/360 [11:11<04:52,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  70%|██████▉   | 251/360 [11:14<04:41,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  70%|███████   | 252/360 [11:17<04:45,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  70%|███████   | 253/360 [11:20<04:57,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  71%|███████   | 254/360 [11:23<04:53,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  71%|███████   | 255/360 [11:25<04:38,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  71%|███████   | 256/360 [11:27<04:31,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  71%|███████▏  | 257/360 [11:30<04:21,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  72%|███████▏  | 258/360 [11:32<04:16,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  72%|███████▏  | 259/360 [11:35<04:16,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  72%|███████▏  | 260/360 [11:37<04:15,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  72%|███████▎  | 261/360 [11:40<04:16,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  73%|███████▎  | 262/360 [11:43<04:14,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  73%|███████▎  | 263/360 [11:45<04:15,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  73%|███████▎  | 264/360 [11:47<03:28,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  74%|███████▎  | 265/360 [11:49<03:25,  2.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  74%|███████▍  | 266/360 [11:51<03:34,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  74%|███████▍  | 267/360 [11:54<03:34,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  74%|███████▍  | 268/360 [11:56<03:42,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  75%|███████▍  | 269/360 [12:00<04:07,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  75%|███████▌  | 270/360 [12:02<04:05,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  75%|███████▌  | 271/360 [12:05<03:50,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  76%|███████▌  | 272/360 [12:08<04:00,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  76%|███████▌  | 273/360 [12:11<03:58,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  76%|███████▌  | 274/360 [12:13<03:45,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  76%|███████▋  | 275/360 [12:15<03:37,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  77%|███████▋  | 276/360 [12:18<03:30,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  77%|███████▋  | 277/360 [12:21<03:46,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  77%|███████▋  | 278/360 [12:23<03:35,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  78%|███████▊  | 279/360 [12:26<03:31,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  78%|███████▊  | 280/360 [12:28<03:27,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  78%|███████▊  | 281/360 [12:31<03:23,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  78%|███████▊  | 282/360 [12:33<03:12,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  79%|███████▊  | 283/360 [12:36<03:10,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  79%|███████▉  | 284/360 [12:38<03:01,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  79%|███████▉  | 285/360 [12:41<03:15,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  79%|███████▉  | 286/360 [12:44<03:12,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  80%|███████▉  | 287/360 [12:46<03:03,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  80%|████████  | 288/360 [12:49<03:08,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  80%|████████  | 289/360 [12:51<03:00,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  81%|████████  | 290/360 [12:54<02:54,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  81%|████████  | 291/360 [12:56<02:53,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  81%|████████  | 292/360 [12:59<02:50,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  81%|████████▏ | 293/360 [13:02<03:08,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  82%|████████▏ | 294/360 [13:05<02:59,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  82%|████████▏ | 295/360 [13:07<02:55,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  82%|████████▏ | 296/360 [13:10<03:01,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  82%|████████▎ | 297/360 [13:13<02:55,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  83%|████████▎ | 298/360 [13:16<02:58,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  83%|████████▎ | 299/360 [13:19<02:59,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  83%|████████▎ | 300/360 [13:21<02:42,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  84%|████████▎ | 301/360 [13:25<02:56,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  84%|████████▍ | 302/360 [13:28<02:53,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  84%|████████▍ | 303/360 [13:31<02:53,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  84%|████████▍ | 304/360 [13:34<02:53,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  85%|████████▍ | 305/360 [13:37<02:41,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  85%|████████▌ | 306/360 [13:40<02:37,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  85%|████████▌ | 307/360 [13:43<02:30,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  86%|████████▌ | 308/360 [13:45<02:17,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  86%|████████▌ | 309/360 [13:47<02:13,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  86%|████████▌ | 310/360 [13:50<02:14,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  86%|████████▋ | 311/360 [13:52<02:05,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  87%|████████▋ | 312/360 [13:55<02:01,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  87%|████████▋ | 313/360 [13:57<01:59,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  87%|████████▋ | 314/360 [14:00<02:00,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  88%|████████▊ | 315/360 [14:02<01:52,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  88%|████████▊ | 316/360 [14:05<01:48,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  88%|████████▊ | 317/360 [14:08<01:48,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  88%|████████▊ | 318/360 [14:11<01:58,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  89%|████████▊ | 319/360 [14:14<01:58,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  89%|████████▉ | 320/360 [14:17<01:52,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  89%|████████▉ | 321/360 [14:18<01:30,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  89%|████████▉ | 322/360 [14:21<01:34,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  90%|████████▉ | 323/360 [14:23<01:33,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  90%|█████████ | 324/360 [14:26<01:29,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  90%|█████████ | 325/360 [14:28<01:27,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  91%|█████████ | 326/360 [14:31<01:25,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  91%|█████████ | 327/360 [14:34<01:27,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  91%|█████████ | 328/360 [14:36<01:19,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  91%|█████████▏| 329/360 [14:39<01:23,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  92%|█████████▏| 330/360 [14:41<01:18,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  92%|█████████▏| 331/360 [14:45<01:20,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  92%|█████████▏| 332/360 [14:47<01:14,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  92%|█████████▎| 333/360 [14:50<01:14,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  93%|█████████▎| 334/360 [14:53<01:11,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  93%|█████████▎| 335/360 [14:55<01:07,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  93%|█████████▎| 336/360 [14:58<01:02,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  94%|█████████▎| 337/360 [15:01<01:02,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  94%|█████████▍| 338/360 [15:04<01:04,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  94%|█████████▍| 339/360 [15:08<01:04,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  94%|█████████▍| 340/360 [15:11<01:03,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  95%|█████████▍| 341/360 [15:13<00:55,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  95%|█████████▌| 342/360 [15:16<00:49,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  95%|█████████▌| 343/360 [15:19<00:47,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  96%|█████████▌| 344/360 [15:22<00:49,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  96%|█████████▌| 345/360 [15:25<00:43,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  96%|█████████▌| 346/360 [15:27<00:39,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  96%|█████████▋| 347/360 [15:30<00:36,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  97%|█████████▋| 348/360 [15:33<00:32,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  97%|█████████▋| 349/360 [15:35<00:30,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  97%|█████████▋| 350/360 [15:38<00:27,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  98%|█████████▊| 351/360 [15:41<00:23,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  98%|█████████▊| 352/360 [15:43<00:20,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  98%|█████████▊| 353/360 [15:46<00:18,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  98%|█████████▊| 354/360 [15:48<00:15,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  99%|█████████▊| 355/360 [15:51<00:12,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  99%|█████████▉| 356/360 [15:54<00:11,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  99%|█████████▉| 357/360 [15:58<00:09,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions:  99%|█████████▉| 358/360 [16:00<00:05,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions: 100%|█████████▉| 359/360 [16:03<00:02,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\rGenerating predictions: 100%|██████████| 360/360 [16:06<00:00,  2.80s/it]\rGenerating predictions: 100%|██████████| 360/360 [16:06<00:00,  2.68s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>explanations</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>You take things that don't belong to you.</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>This sentence is labeled as abuse because it d...</td>\n",
       "      <td>ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I take it you don't want to be characterised i...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "      <td>This sentence is labeled as not abusive becaus...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>You are so imaginative at what could go wrong.</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "      <td>This sentence is labeled as abuse because it u...</td>\n",
       "      <td>ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>You need to act your age.</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>This sentence is labeled as abuse because it u...</td>\n",
       "      <td>ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I think you might be challenged vertically.</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>This sentence is labeled as abuse because it u...</td>\n",
       "      <td>ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>356</td>\n",
       "      <td>You really carry on talking, regardless of the...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "      <td>This sentence is labeled as not abusive becaus...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>357</td>\n",
       "      <td>You are the reason I have decided to spend mor...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "      <td>This sentence is labeled as not abusive becaus...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>358</td>\n",
       "      <td>You have always given me amazing vibes.</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "      <td>This sentence is labeled as not abusive becaus...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>359</td>\n",
       "      <td>It's great that no one notices you when you sh...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "      <td>This sentence is labeled as abuse because it u...</td>\n",
       "      <td>ABUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>360</td>\n",
       "      <td>You could be funny sometimes.</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>This sentence is labeled as not abusive becaus...</td>\n",
       "      <td>NONE ABUSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id                                               text      labels  \\\n",
       "0          1          You take things that don't belong to you.       ABUSE   \n",
       "1          2  I take it you don't want to be characterised i...  NONE ABUSE   \n",
       "2          3     You are so imaginative at what could go wrong.  NONE ABUSE   \n",
       "3          4                          You need to act your age.       ABUSE   \n",
       "4          5        I think you might be challenged vertically.       ABUSE   \n",
       "..       ...                                                ...         ...   \n",
       "355      356  You really carry on talking, regardless of the...  NONE ABUSE   \n",
       "356      357  You are the reason I have decided to spend mor...  NONE ABUSE   \n",
       "357      358            You have always given me amazing vibes.  NONE ABUSE   \n",
       "358      359  It's great that no one notices you when you sh...  NONE ABUSE   \n",
       "359      360                      You could be funny sometimes.       ABUSE   \n",
       "\n",
       "                                          explanations predictions  \n",
       "0    This sentence is labeled as abuse because it d...       ABUSE  \n",
       "1    This sentence is labeled as not abusive becaus...  NONE ABUSE  \n",
       "2    This sentence is labeled as abuse because it u...       ABUSE  \n",
       "3    This sentence is labeled as abuse because it u...       ABUSE  \n",
       "4    This sentence is labeled as abuse because it u...       ABUSE  \n",
       "..                                                 ...         ...  \n",
       "355  This sentence is labeled as not abusive becaus...  NONE ABUSE  \n",
       "356  This sentence is labeled as not abusive becaus...  NONE ABUSE  \n",
       "357  This sentence is labeled as not abusive becaus...  NONE ABUSE  \n",
       "358  This sentence is labeled as abuse because it u...       ABUSE  \n",
       "359  This sentence is labeled as not abusive becaus...  NONE ABUSE  \n",
       "\n",
       "[360 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data(dataset_csv, examples_file, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.7831\n",
      "Recall: 0.7472\n",
      "F1 Score: 0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longju/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/longju/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/longju/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(predictions_path):\n",
    "    # Load the predictions dataframe\n",
    "    predictions_df = pd.read_csv(predictions_path)\n",
    "    \n",
    "    # Extract true labels and predicted labels\n",
    "    true_labels = predictions_df['labels']\n",
    "    predicted_labels = predictions_df['predictions']\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "    \n",
    "    # Extract precision, recall, and F1 score for each class\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "evaluate(output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63a59f273878d21d9c11a68929f8708312fda201dd9668999f076f8cf65bfd79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
